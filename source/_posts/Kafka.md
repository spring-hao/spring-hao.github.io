---
title: Kafka
date: 2023-07-16 21:04:13
categories: 
- 工具
tags: 

---

## kafka介绍

Apache Kafka 是消息引擎系统，也是一个分布式流处理平台，企业利用它可以在A、B两个系统之间传递**消息**，实现松耦合的异步数据传输。总的来说，消息引擎具有两个重要能力：

- 消息引擎传输的对象是**消息**
- 定义了传输消息的**规范**

消息引擎不在乎A、B两个系统是否相同，它可以在不同系统间传递消息，因此消息的通用格式以及如何传输消息至关重要。kafka的消息格式化使用的是二进制字节序列，消息还是结构化的，只是在使用之前都要将其转换成二进制的字节序列。kafka支持两种常用的消息引擎模型：

- 点对点模型：也叫消息队列模型，消息只能由A系统发出，由B系统接收，其他模型无权生产与消费消息，简单来说是一对一的模型。
- 发布 / 订阅模型：有一个topic的概念，可以有多个生产者向topic中生产消息，同时允许多个消费者订阅topic进行消费，简单来说就是一种多对多的模型。

### 概念说明

向目标topic发送消息的客户端被称为消费者，消费者源源不断的向**一个或多个**主题发送消息，而订阅这些topic的客户端被称为消费者，消费者同样订阅**一个或多个**topic。生产者和消费者统称为**客户端**，客户端可以运行多个实例，这些实例不停地进行生产和消费行为。



Kafka 的服务器端由被称为 Broker 的服务进程构成，即**一个 Kafka 集群由多个 Broker 组成**，Broker 负责接收和处理客户端发送过来的请求，以及对**消息进行持久化**。虽然多个 Broker 进程能够运行在同一台机器上，但更常见的做法是将不同的 Broker 分散运行在不同的机器上，这样如果**集群**中某一台机器宕机，即使在它上面运行的所有 Broker 进程都挂掉了，其他机器上的 Broker 也依然能够对外提供服务。这就是 Kafka 提供高可用的手段之一。

为了实现高可用目标，kafka还会对消息进行备份，这些备份的数据在kafka中叫做**副本**。副本的数量可以配置，这些副本保存着相同的数据，但却有不同的角色和作用。Kafka 定义了两类副本：

- 领导者副本（Leader Replica）：领导者副本对客户端**提供服务**。
- 追随者副本（Follower Replica）：**不对外提供服务**，只是被动的追随领导者副本。

生产者总是向领导者副本写消息；而消费者总是从领导者副本读消息。至于追随者副本，它只向领导者副本发送请求，请求领导者把最新生产的消息发给它，这样它能保持与领导者的同步。**副本机制保证了消息的持久化**。为了保证领导者副本保存的内容不会爆满，kafka对每个topic划分为多个分区，每个分区是一组有序地消息日志。生产者生产的消息只会被发送到同一topic下的某一个分区中，kafka的分区编号从0开始。

副本是在分区这个级别下定义的。每个分区可以配置n个副本，其中领导者副本只能有1个，其余都是追随者副本。生产者向分区写入消息，每条消息在分区内由一个偏移量（offset）来表示其位置，其中偏移量编号从0开始，一旦消息被成功写入到一个分区上，它的位移值就是固定的了。

总的来说，Kafka 使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写（Append-only）消息的物理文件。因为只能追加写入，故避免了缓慢的随机 I/O 操作，改为性能较好的顺序 I/O 写操作，这也是实现 Kafka 高吞吐量特性的一个重要手段。因此kafka通过日志段（Log Segment）机制来定期地删除消息以回收磁盘。在 Kafka 底层，一个日志又进一步细分成多个日志段，消息被追加写到当前最新的日志段中，当写满了一个日志段后，Kafka 会自动切分出一个新的日志段，并将老的日志段封存起来。Kafka 在后台还有定时任务会定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。

每个消费者在消费消息的过程使用消费者位移（Consumer Offset）字段记录它当前消费到了分区的哪个位置，消费者位移可能是随时变化的，每个消费者有着自己的消费者位移。



- 消息：Record。Kafka 是消息引擎嘛，这里的消息就是指 Kafka 处理的主要对象。
- 主题：Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。
- 分区：Partition。一个有序不变的消息序列。每个主题下可以有多个分区。
- 消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。
- 副本：Replica。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追
- 随者副本，各自有不同的角色划分。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。
- 生产者：Producer。向主题发布新消息的应用程序。
- 消费者：Consumer。从主题订阅新消息的应用程序。
- 消费者位移：Consumer Offset。表征消费者消费进度，每个消费者都有自己的消费者位移。
- 消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。
- 重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。

![image-20230712110937524](Kafka/image-20230712110937524.png)



## 客户端实践

### 消息分区机制

kafka的主题是承载消息的逻辑容器，在每个主题下还有很多个分区，消息最终保存在不同的分区下，主题下的消息只会保存在一个分区中，而不会在多个分区中保存多份。分区的目的就是为了负载均衡、实现系统的高伸缩性，不同的分区可以放在不同的机器上，数据的读写操作针对分区进行，即使某一分区挂掉也不影响其他分区继续提供服务。

**分区策略可以决定消费者将消息发送到哪个分区。**kafka提供多种分区策略，同时支持自定义分区策略，只需配置生产端的参数`partitioner.class`以及实现`org.apache.kafka.clients.producer.Partitioner`接口。

#### 轮询策略

也就是顺序分配，即消息按照分区挨个发送。

![image-20230712113230478](Kafka/image-20230712113230478.png)

轮询策略是 Kafka Java 生产者 API 默认提供的分区策略。轮询策略有非常**优秀的负载均衡表现**，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是最常用的分区策略之一。

#### 随机策略

随机的将消息发送到某一分区。本质上看随机策略也是力求将数据均匀地打散到各个分区，但从实际表现来看，它要**逊于轮询策略**，所以如果追求数据的均匀分布，还是使用轮询策略比较好。

#### 按消息键保存策略

Kafka 允许为每条消息定义消息键，简称为 Key。Key可以是一个有着明确业务含义的字符串，比如客户代码、部门编号或是业务 ID 等；也可以用来表征消息元数据。一旦消息被定义了 Key，那么你就可以保证同一个 Key 的所有消息都进入到相同的分区里面，由于每个分区下的消息处理都是有顺序的，故这个策略被称为按消息键保序策略。

如果指定了 Key，那么kafka默认实现按消息键保序策略；如果没有指定 Key，则使用轮询策略。

### 消息压缩

压缩秉承了时间换空间的经典思想，指的是用少量的cpu时间去换磁盘或网络传输量。因此启用压缩的条件就是：

- Producer 程序运行机器上的 CPU 资源要很充足。
- 网络带宽资源实在有限。

kafka的消息包含两层：消息集合以及消息。一个消息集合包含若干条日志项，**日志项是真正封存消息的地方**，kafka底层的消息日志由若干消息集合组成，它通常不会操作具体的某条消息，总是在消息集合层面进行写入操作。

在kafka中，消息压缩可能发生在两个地方：生产者端和broker端。

生产者端设置了消息压缩格式后，任何消息集合都会经过压缩后发送给broker，可以很好的节省网络贷款。通常情况下，broker只会原封不动的接收消息，除了一下条件：

- broker端指定了和生产者端不同的压缩算法：此时只能解压缩后再次压缩。
- broker发生了消息格式转换。为了兼容老版本的格式，Broker 端会对新版本消息执行向老版本格式的转换。这个过程中会涉及消息的解压缩和重新压缩。

多数情况下压缩发生在生产端，压缩后的消息发送到broker之后保存下来，当消费者请求这些消息时，broker会把消息发送出去，当消息到达消费端时自行解压缩还原成原来的消息。Kafka 会将启用了哪种压缩算法**封装**进消息集合中，这样当 Consumer 读取到消息集合时，它自然就知道了这些消息使用的是哪种压缩算法。

### 消息无丢失的保证

kafka只对**已提交**的消息做**有限度**的持久化保存。

- 已提交的消息：当Kafka的**若干个broker**接收到消息并写入日志文件中，会返回一个成功消息给生产者，此时Kafka认为消息已经成功提交。若干个取决于客户端的配置，可以是一个也可以是多个。
- 有限度：Kafka不丢失消息的前提是保存消息的多个broker**最少要有一个**存活，只有这样，Kafka才能保证消息不会丢失。

容易丢失消息的场景：

1. 客户端发送消息是异步的，在没有成功接收到返回值时，Kafka不认为这个消息是成功提交的，因此通常用`producer.send(msg, callback)`来进行调用，回调函数可以告诉客户端消息是否成功发送到broker。
2. 消费者要维持先消费消息，再移动offset的顺序进行操作，防止offset偏离，这样做可以最大程度保证消息不丢失，但是可能出现消费端重复消费的问题。
3. 如果是多线程异步处理消费消息，Consumer 程序不要开启自动提交位移，而是要应用程序手动提交位移。